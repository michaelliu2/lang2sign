{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "en-asl-train_open_nmt_transformer_glove_embeddings.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ntr5kTLfv4L",
        "colab_type": "code",
        "outputId": "706e1f80-1af2-41ad-86f5-1edb00bc2ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        }
      },
      "source": [
        "!pip install OpenNMT-tf"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting OpenNMT-tf\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/c8/f547b9de14be375abe282fa90b460730b1837ecac774db0aceee18f73945/OpenNMT_tf-1.25.0-py2.py3-none-any.whl (150kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 6.3MB/s \n",
            "\u001b[?25hCollecting pyonmttok<2,>=1.11.0; platform_system == \"Linux\" (from OpenNMT-tf)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/bc/d9a58127fbc28acf207fdfb027041fcc887d68f223328d2be81a525ce4da/pyonmttok-1.15.7-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 38.9MB/s \n",
            "\u001b[?25hCollecting rouge==0.3.1 (from OpenNMT-tf)\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/89/af359c22e1d858e0299d4cc9219f36b504817c9797acad23081247867845/rouge-0.3.1-py3-none-any.whl\n",
            "Collecting sacrebleu==1.*; python_version >= \"3.0\" (from OpenNMT-tf)\n",
            "  Downloading https://files.pythonhosted.org/packages/0b/58/f7b07a9eb4a39adeea22c46554a51432785fe5812770334c208da926577f/sacrebleu-1.4.1-py3-none-any.whl\n",
            "Collecting pyyaml>=5.1 (from OpenNMT-tf)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu==1.*; python_version >= \"3.0\"->OpenNMT-tf) (3.7.4.1)\n",
            "Collecting portalocker (from sacrebleu==1.*; python_version >= \"3.0\"->OpenNMT-tf)\n",
            "  Downloading https://files.pythonhosted.org/packages/60/ec/836a494dbaa72541f691ec4e66f29fdc8db9bcc7f49e1c2d457ba13ced42/portalocker-1.5.1-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl size=44104 sha256=bdd8b0d9071455deaee985da0736d192b867ce0de7edc746f4ee3174ec1d09fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyonmttok, rouge, portalocker, sacrebleu, pyyaml, OpenNMT-tf\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed OpenNMT-tf-1.25.0 portalocker-1.5.1 pyonmttok-1.15.7 pyyaml-5.1.2 rouge-0.3.1 sacrebleu-1.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2kjk36GDWOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "b0219dcf-3d7a-425f-8826-1c4835e05d80"
      },
      "source": [
        "!git clone https://github.com/OpenNMT/OpenNMT-tf.git"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'OpenNMT-tf'...\n",
            "remote: Enumerating objects: 480, done.\u001b[K\n",
            "remote: Counting objects: 100% (480/480), done.\u001b[K\n",
            "remote: Compressing objects: 100% (356/356), done.\u001b[K\n",
            "remote: Total 18256 (delta 320), reused 237 (delta 123), pack-reused 17776\u001b[K\n",
            "Receiving objects: 100% (18256/18256), 15.56 MiB | 16.60 MiB/s, done.\n",
            "Resolving deltas: 100% (14670/14670), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kJrZlf52dHz",
        "colab_type": "code",
        "outputId": "e2df38eb-fc6a-4917-8a89-2334ab338320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "!rm -rf lang2sign\n",
        "!git clone https://github.com/monkeyhippies/lang2sign.git\n",
        "!cd lang2sign && git checkout open-nmt"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'lang2sign'...\n",
            "remote: Enumerating objects: 155, done.\u001b[K\n",
            "remote: Counting objects: 100% (155/155), done.\u001b[K\n",
            "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
            "remote: Total 155 (delta 56), reused 127 (delta 30), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (155/155), 289.07 KiB | 1.06 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n",
            "Branch 'open-nmt' set up to track remote branch 'open-nmt' from 'origin'.\n",
            "Switched to a new branch 'open-nmt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCpJZCnQ2reZ",
        "colab_type": "code",
        "outputId": "ca513f5d-1b9e-4b7b-d5ca-d2cf85ae791e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        }
      },
      "source": [
        "!cd lang2sign && make data"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./utils/download_en_asl_gloss_data.sh\n",
            "--2019-09-21 04:49:14--  https://raw.githubusercontent.com/monkeyhippies/speech2signs-2017-nmt/master/ASLG-PC12/train.tgz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3765908 (3.6M) [application/octet-stream]\n",
            "Saving to: ‘data/raw/lang2gloss/enasl/train.tgz’\n",
            "\n",
            "\rtrain.tgz             0%[                    ]       0  --.-KB/s               \rtrain.tgz           100%[===================>]   3.59M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-09-21 04:49:14 (80.9 MB/s) - ‘data/raw/lang2gloss/enasl/train.tgz’ saved [3765908/3765908]\n",
            "\n",
            "train/\n",
            "train/ENG-ASL_Train_0.046.asl\n",
            "train/ENG-ASL_Train_0.046.en\n",
            "--2019-09-21 04:49:14--  https://raw.githubusercontent.com/monkeyhippies/speech2signs-2017-nmt/master/ASLG-PC12/dev.tgz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 100488 (98K) [application/octet-stream]\n",
            "Saving to: ‘data/raw/lang2gloss/enasl/dev.tgz’\n",
            "\n",
            "\rdev.tgz               0%[                    ]       0  --.-KB/s               \rdev.tgz             100%[===================>]  98.13K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-09-21 04:49:14 (5.83 MB/s) - ‘data/raw/lang2gloss/enasl/dev.tgz’ saved [100488/100488]\n",
            "\n",
            "dev/\n",
            "dev/ENG-ASL_Dev_0.046.en\n",
            "dev/ENG-ASL_Dev_0.046.asl\n",
            "--2019-09-21 04:49:14--  https://raw.githubusercontent.com/monkeyhippies/speech2signs-2017-nmt/master/ASLG-PC12/test.tgz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 199564 (195K) [application/octet-stream]\n",
            "Saving to: ‘data/raw/lang2gloss/enasl/test.tgz’\n",
            "\n",
            "test.tgz            100%[===================>] 194.89K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-09-21 04:49:15 (11.4 MB/s) - ‘data/raw/lang2gloss/enasl/test.tgz’ saved [199564/199564]\n",
            "\n",
            "test/\n",
            "test/ENG-ASL_Test_0.046.asl\n",
            "test/ENG-ASL_Test_0.046.en\n",
            "./utils/preprocess_en_asl_gloss_data.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKUCzUwW3E5b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "a5a13b35-5cf1-49d0-e9e1-dd1d03bc0d9d"
      },
      "source": [
        "!cd lang2sign && make word-embeddings"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./utils/download_glove_embeddings.sh\n",
            "--2019-09-21 04:49:16--  http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.6B.zip [following]\n",
            "--2019-09-21 04:49:16--  https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip [following]\n",
            "--2019-09-21 04:49:17--  http://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182753 (822M) [application/zip]\n",
            "Saving to: ‘pretrained-embeddings/glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  19.4MB/s    in 44s     \n",
            "\n",
            "2019-09-21 04:50:01 (18.8 MB/s) - ‘pretrained-embeddings/glove.6B.zip’ saved [862182753/862182753]\n",
            "\n",
            "Archive:  pretrained-embeddings//glove.6B.zip\n",
            "  inflating: pretrained-embeddings/glove.6B.100d.txt  \n",
            "  inflating: pretrained-embeddings/glove.6B.200d.txt  \n",
            "  inflating: pretrained-embeddings/glove.6B.300d.txt  \n",
            "  inflating: pretrained-embeddings/glove.6B.50d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnylHNOfkzZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4cab68e-3849-4b7a-b8b9-09d94ca256e5"
      },
      "source": [
        "!ls lang2sign/configs/open-nmt/models/transformer_shared_embedding.py\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lang2sign/configs/open-nmt/models/transformer_shared_embedding.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4sWsK3vk2Mw",
        "colab_type": "code",
        "outputId": "345ae384-df23-426a-e3db-6321f1407163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cd lang2sign && onmt-main train_and_eval --model configs/open-nmt/models/transformer_shared_embedding.py --config configs/open-nmt/transformer-glove-embeddings.yaml"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/decoders/rnn_decoder.py:435: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/optimizers/adafactor.py:32: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/optimizers/multistep_adam.py:36: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/bin/main.py:111: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/bin/main.py:111: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/bin/main.py:145: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/bin/main.py:146: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Creating model directory models/transformer-glove/\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/bin/main.py:147: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "2019-09-21 04:50:35.186546: W tensorflow/python/util/util.cc:280] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/bin/main.py:154: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/bin/main.py:157: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "INFO:tensorflow:Using parameters:\n",
            "data:\n",
            "  eval_features_file: data/preprocessed/lang2gloss/enasl/dev/ENG-ASL_Dev_0.046.en\n",
            "  eval_labels_file: data/preprocessed/lang2gloss/enasl/dev/ENG-ASL_Dev_0.046.asl\n",
            "  source_embedding:\n",
            "    case_insensitive: true\n",
            "    path: pretrained-embeddings/glove.6B.300d.txt\n",
            "    trainable: true\n",
            "    with_header: false\n",
            "  source_words_vocabulary: pretrained-embeddings/glove.6B.300d.vocab\n",
            "  target_words_vocabulary: pretrained-embeddings/glove.6B.300d.vocab\n",
            "  train_features_file: data/preprocessed/lang2gloss/enasl/train/ENG-ASL_Train_0.046.en\n",
            "  train_labels_file: data/preprocessed/lang2gloss/enasl/train/ENG-ASL_Train_0.046.asl\n",
            "eval:\n",
            "  batch_size: 30\n",
            "  eval_delay: 7200\n",
            "  exporters: last\n",
            "  external_evaluators: sacreBLEU\n",
            "  num_threads: 1\n",
            "  prefetch_buffer_size: 1\n",
            "  save_eval_predictions: false\n",
            "infer:\n",
            "  batch_size: 10\n",
            "  bucket_width: 5\n",
            "  n_best: 1\n",
            "  num_threads: 1\n",
            "  prefetch_buffer_size: 1\n",
            "  with_alignments: null\n",
            "  with_scores: false\n",
            "model_dir: models/transformer-glove/\n",
            "params:\n",
            "  decoding_noise:\n",
            "  - dropout: 0.1\n",
            "  learning_rate: 2.0\n",
            "  optimizer: AdamOptimizer\n",
            "  optimizer_params:\n",
            "    beta1: 0.8\n",
            "    beta2: 0.998\n",
            "score:\n",
            "  batch_size: 64\n",
            "  num_threads: 1\n",
            "  prefetch_buffer_size: 1\n",
            "  with_alignments: null\n",
            "  with_token_level: false\n",
            "train:\n",
            "  average_last_checkpoints: 8\n",
            "  batch_size: 128\n",
            "  batch_type: tokens\n",
            "  bucket_width: 5\n",
            "  keep_checkpoint_max: 3\n",
            "  maximum_features_length: 70\n",
            "  maximum_labels_length: 70\n",
            "  num_threads: 4\n",
            "  prefetch_buffer_size: null\n",
            "  sample_buffer_size: 500000\n",
            "  save_checkpoints_steps: 10000\n",
            "  save_summary_steps: 1000\n",
            "  single_pass: false\n",
            "  train_steps: 1000000\n",
            "\n",
            "2019-09-21 04:50:37.017547: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-09-21 04:50:37.018228: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1c9a840 executing computations on platform Host. Devices:\n",
            "2019-09-21 04:50:37.018281: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-09-21 04:50:37.043160: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-09-21 04:50:37.159179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-21 04:50:37.160027: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1c9af40 executing computations on platform CUDA. Devices:\n",
            "2019-09-21 04:50:37.160059: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-09-21 04:50:37.160555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-21 04:50:37.161269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-21 04:50:37.162074: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-21 04:50:37.169630: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-21 04:50:37.172855: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-21 04:50:37.174250: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-21 04:50:37.255236: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-21 04:50:37.260943: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-21 04:50:37.366424: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-21 04:50:37.366753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-21 04:50:37.368137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-21 04:50:37.368899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-21 04:50:37.369085: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-21 04:50:37.370813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-21 04:50:37.370853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-21 04:50:37.370873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-21 04:50:37.371410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-21 04:50:37.372204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-21 04:50:37.372885: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-09-21 04:50:37.372943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/utils/evaluator.py:26: The name tf.summary.FileWriterCache is deprecated. Please use tf.compat.v1.summary.FileWriterCache instead.\n",
            "\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'models/transformer-glove/', '_tf_random_seed': None, '_save_summary_steps': 1000, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': gpu_options {\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    layout_optimizer: OFF\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7f9a608c18>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 10000 or save_checkpoints_secs None.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Training on 83619 examples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/tokenizers/tokenizer.py:277: calling string_split (from tensorflow.python.ops.ragged.ragged_string_ops) with delimiter is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "delimiter is deprecated, please use sep instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/lookup_ops.py:978: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/utils/compat.py:64: The name tf.data.get_output_shapes is deprecated. Please use tf.compat.v1.data.get_output_shapes instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/estimator.py:129: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/estimator.py:131: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/estimator.py:131: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/utils/parallel.py:143: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/models/transformer.py:136: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/encoders/self_attention_encoder.py:59: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/layers/transformer.py:136: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv1D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/models/sequence_to_sequence.py:201: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/estimator.py:262: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/inputters/text_inputter.py:44: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/inputters/text_inputter.py:47: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/inputters/text_inputter.py:75: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/utils/hooks.py:132: The name tf.train.SecondOrStepTimer is deprecated. Please use tf.estimator.SecondOrStepTimer instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Number of trainable parameters: 125037898\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/opennmt/utils/hooks.py:159: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
            "\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "2019-09-21 04:51:58.225177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-21 04:51:58.225987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-21 04:51:58.226090: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-21 04:51:58.226124: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-21 04:51:58.226148: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-21 04:51:58.226174: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-21 04:51:58.226198: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-21 04:51:58.226220: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-21 04:51:58.226244: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-21 04:51:58.226355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-21 04:51:58.227092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-21 04:51:58.227749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-21 04:51:58.227808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-21 04:51:58.227824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-21 04:51:58.227835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-21 04:51:58.227961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-21 04:51:58.228699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-21 04:51:58.229377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2019-09-21 04:51:58.607662: W tensorflow/core/framework/allocator.cc:107] Allocation of 480002400 exceeds 10% of system memory.\n",
            "2019-09-21 04:51:58.712353: W tensorflow/core/framework/allocator.cc:107] Allocation of 480002400 exceeds 10% of system memory.\n",
            "2019-09-21 04:51:58.877850: W tensorflow/core/framework/allocator.cc:107] Allocation of 480002400 exceeds 10% of system memory.\n",
            "2019-09-21 04:51:58.964542: W tensorflow/core/framework/allocator.cc:107] Allocation of 480002400 exceeds 10% of system memory.\n",
            "2019-09-21 04:51:59.474043: W tensorflow/core/framework/allocator.cc:107] Allocation of 480002400 exceeds 10% of system memory.\n",
            "2019-09-21 04:52:05.282254: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "2019-09-21 04:52:05.673711: I tensorflow/core/kernels/lookup_util.cc:376] Table trying to initialize from file pretrained-embeddings/glove.6B.300d.vocab is already initialized.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "tcmalloc: large alloc 1233903616 bytes == 0x13ca44000 @  0x7f7ff477b615 0x566e55 0x56f1bf 0x57f4fb 0x5afb98 0x4f862c 0x4f98c7 0x4f6128 0x4f7d60 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d\n",
            "tcmalloc: large alloc 1542381568 bytes == 0xd2bc4000 @  0x7f7ff477b615 0x566e55 0x56f1bf 0x57f4fb 0x5afb98 0x4f862c 0x4f98c7 0x4f6128 0x4f7d60 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d\n",
            "tcmalloc: large alloc 1927979008 bytes == 0x12eab2000 @  0x7f7ff477b615 0x566e55 0x56f1bf 0x57f4fb 0x5afb98 0x4f862c 0x4f98c7 0x4f6128 0x4f7d60 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d\n",
            "tcmalloc: large alloc 2409979904 bytes == 0x7f7eb9b98000 @  0x7f7ff477b615 0x566e55 0x56f1bf 0x57f4fb 0x5afb98 0x4f862c 0x4f98c7 0x4f6128 0x4f7d60 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d\n",
            "tcmalloc: large alloc 3012476928 bytes == 0xd2bc4000 @  0x7f7ff477b615 0x566e55 0x56f1bf 0x57f4fb 0x5afb98 0x4f862c 0x4f98c7 0x4f6128 0x4f7d60 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d\n",
            "tcmalloc: large alloc 3765600256 bytes == 0x7f7dd9470000 @  0x7f7ff477b615 0x566e55 0x56f1bf 0x57f4fb 0x5afb98 0x4f862c 0x4f98c7 0x4f6128 0x4f7d60 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d\n",
            "tcmalloc: large alloc 4707000320 bytes == 0x7f7cc0b7e000 @  0x7f7ff477b615 0x566e55 0x56f1bf 0x57f4fb 0x5afb98 0x4f862c 0x4f98c7 0x4f6128 0x4f7d60 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f7a28 0x4f876d\n",
            "INFO:tensorflow:Saving checkpoints for 0 into models/transformer-glove/model.ckpt.\n",
            "2019-09-21 04:53:57.592976: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "INFO:tensorflow:loss = 773.0916, step = 0\n",
            "INFO:tensorflow:global_step/sec: 3.3391\n",
            "INFO:tensorflow:loss = 94319.375, step = 1000 (299.483 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.36324\n",
            "INFO:tensorflow:loss = 24751.969, step = 2000 (297.333 sec)\n",
            "INFO:tensorflow:source_words/sec: 323\n",
            "INFO:tensorflow:target_words/sec: 314\n",
            "INFO:tensorflow:global_step/sec: 3.35391\n",
            "INFO:tensorflow:loss = 101351.086, step = 3000 (298.159 sec)\n",
            "INFO:tensorflow:source_words/sec: 322\n",
            "INFO:tensorflow:target_words/sec: 313\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}