{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "en-asl-train_transformer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoNY58qpMTdU",
        "colab_type": "text"
      },
      "source": [
        "## Train transformer to translate English to ASL\n",
        "We use the tensor2tensor library to train a transformer on a subset of the ASLG-PC12 dataset. Much of this code was copied and editted from the [tensor2tensor github repo](https://github.com/tensorflow/tensor2tensor). This code can readily be run in google colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrU7TAYh92yv",
        "colab_type": "code",
        "outputId": "0e9626d2-eecd-4de7-ef56-82de4f560d7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensor2tensor[tensorflow_gpu]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensor2tensor[tensorflow_gpu] in /usr/local/lib/python3.6/dist-packages (1.11.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (1.3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (2.21.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (1.1.1)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (0.98)\n",
            "Requirement already satisfied: gevent in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (1.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (1.12.0)\n",
            "Requirement already satisfied: tfds-nightly in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (1.2.0.dev201909050105)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (1.16.5)\n",
            "Requirement already satisfied: gunicorn in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (19.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (4.28.1)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (0.10.11)\n",
            "Requirement already satisfied: mesh-tensorflow in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (0.0.5)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (1.1.1)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (0.7.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (1.7.11)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (4.1.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from tensor2tensor[tensorflow_gpu]) (2.8.0)\n",
            "Collecting tensorflow-gpu>=1.12.0; extra == \"tensorflow_gpu\" (from tensor2tensor[tensorflow_gpu])\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 57kB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->tensor2tensor[tensorflow_gpu]) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->tensor2tensor[tensorflow_gpu]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->tensor2tensor[tensorflow_gpu]) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->tensor2tensor[tensorflow_gpu]) (2.8)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy->tensor2tensor[tensorflow_gpu]) (1.1.0)\n",
            "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent->tensor2tensor[tensorflow_gpu]) (0.4.15)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor[tensorflow_gpu]) (3.7.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor[tensorflow_gpu]) (0.8.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor[tensorflow_gpu]) (0.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor[tensorflow_gpu]) (1.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor[tensorflow_gpu]) (1.11.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor[tensorflow_gpu]) (2.2.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor[tensorflow_gpu]) (0.14.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor[tensorflow_gpu]) (5.4.8)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from tfds-nightly->tensor2tensor[tensorflow_gpu]) (19.1.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->tensor2tensor[tensorflow_gpu]) (1.4.3)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask->tensor2tensor[tensorflow_gpu]) (0.15.6)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask->tensor2tensor[tensorflow_gpu]) (7.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask->tensor2tensor[tensorflow_gpu]) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask->tensor2tensor[tensorflow_gpu]) (2.10.1)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->tensor2tensor[tensorflow_gpu]) (0.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->tensor2tensor[tensorflow_gpu]) (4.4.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->tensor2tensor[tensorflow_gpu]) (3.0.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->tensor2tensor[tensorflow_gpu]) (0.0.3)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->tensor2tensor[tensorflow_gpu]) (0.11.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client->tensor2tensor[tensorflow_gpu]) (1.4.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client->tensor2tensor[tensorflow_gpu]) (0.4.7)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client->tensor2tensor[tensorflow_gpu]) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client->tensor2tensor[tensorflow_gpu]) (0.2.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.12.0; extra == \"tensorflow_gpu\"->tensor2tensor[tensorflow_gpu]) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.12.0; extra == \"tensorflow_gpu\"->tensor2tensor[tensorflow_gpu]) (1.14.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.12.0; extra == \"tensorflow_gpu\"->tensor2tensor[tensorflow_gpu]) (1.14.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.12.0; extra == \"tensorflow_gpu\"->tensor2tensor[tensorflow_gpu]) (0.33.6)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.12.0; extra == \"tensorflow_gpu\"->tensor2tensor[tensorflow_gpu]) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.12.0; extra == \"tensorflow_gpu\"->tensor2tensor[tensorflow_gpu]) (0.8.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.12.0; extra == \"tensorflow_gpu\"->tensor2tensor[tensorflow_gpu]) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.12.0; extra == \"tensorflow_gpu\"->tensor2tensor[tensorflow_gpu]) (0.1.7)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.12.0; extra == \"tensorflow_gpu\"->tensor2tensor[tensorflow_gpu]) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tfds-nightly->tensor2tensor[tensorflow_gpu]) (41.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tfds-nightly->tensor2tensor[tensorflow_gpu]) (1.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask->tensor2tensor[tensorflow_gpu]) (1.1.1)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client->tensor2tensor[tensorflow_gpu]) (3.1.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu>=1.12.0; extra == \"tensorflow_gpu\"->tensor2tensor[tensorflow_gpu]) (3.1.1)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCw-zLsvj9vw",
        "colab_type": "code",
        "outputId": "e6c1ae35-06a5-48ea-cedc-4710f9e55fa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Hack to copy en-asl problem onto filesystem\n",
        "!rm -rf 810a33b852eff8689b46cbb5540f5bd9\n",
        "!rm -rf /tmp\n",
        "!rm -rf t2t_data/\n",
        "!rm -rf t2t_train/\n",
        "!git clone https://gist.github.com/monkeyhippies/810a33b852eff8689b46cbb5540f5bd9\n",
        "!mv 810a33b852eff8689b46cbb5540f5bd9 tensor2tensor_problems\n",
        "!touch tensor2tensor_problems/__init__.py\n",
        "! echo -n \"from . import new_problem\" > tensor2tensor_problems/__init__.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '810a33b852eff8689b46cbb5540f5bd9'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 29 (delta 8), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (29/29), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0WIAxrl9Xv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p /content/t2t_data /tmp/t2t_datagen /content/t2t_train/translate_enasl/transformer-transformer_base_single_gpu\n",
        "\n",
        "# Generate data\n",
        "!t2t-datagen --t2t_usr_dir tensor2tensor_problems/\\\n",
        "  --data_dir=/content/t2t_data \\\n",
        "  --tmp_dir=/tmp/t2t_datagen \\\n",
        "  --problem=translate_enasl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abOmj6vX-kiK",
        "colab_type": "code",
        "outputId": "5211374a-a3ab-4480-c2b0-e79cf92c344a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train\n",
        "!t2t-trainer \\\n",
        "  --t2t_usr_dir tensor2tensor_problems/ \\\n",
        "  --data_dir=/content/t2t_data \\\n",
        "  --problem=translate_enasl \\\n",
        "  --model=transformer \\\n",
        "  --train_steps=8000 \\\n",
        "  --hparams_set=transformer_tiny \\\n",
        "  --output_dir=/content/t2t_train/translate_enasl/transformer-transformer_tiny"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0919 06:59:00.751682 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0919 06:59:01.434118 140617721808768 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0919 06:59:03.088742 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0919 06:59:03.089176 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0919 06:59:03.095778 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/mesh_tensorflow/ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\n",
            "\n",
            "W0919 06:59:03.096606 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/mesh_tensorflow/ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
            "\n",
            "W0919 06:59:03.143102 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:105: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.\n",
            "\n",
            "W0919 06:59:03.683417 140617721808768 deprecation_wrapper.py:119] From /usr/local/bin/t2t-trainer:32: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0919 06:59:03.683645 140617721808768 deprecation_wrapper.py:119] From /usr/local/bin/t2t-trainer:32: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0919 06:59:03.683784 140617721808768 deprecation_wrapper.py:119] From /usr/local/bin/t2t-trainer:33: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            ":::MLPv0.5.0 transformer 1568876343.942243099 (/usr/local/bin/t2t-trainer:28) run_set_random_seed\n",
            "I0919 06:59:03.942277 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876343.942243099 (/usr/local/bin/t2t-trainer:28) run_set_random_seed\n",
            "W0919 06:59:03.942689 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:789: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "W0919 06:59:03.943830 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/usr_dir.py:42: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "I0919 06:59:03.943973 140617721808768 usr_dir.py:43] Importing user module tensor2tensor_problems from path /content\n",
            "W0919 06:59:03.944734 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:142: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "I0919 06:59:03.944905 140617721808768 trainer_lib.py:157] Loading hparams from existing json /content/t2t_train/translate_enasl/transformer-transformer_tiny/hparams.json\n",
            "W0919 06:59:03.945065 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:158: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0919 06:59:03.947006 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:117: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.\n",
            "\n",
            "W0919 06:59:03.947228 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:123: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "W0919 06:59:03.947443 140617721808768 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/trainer_lib.py:278: __init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "I0919 06:59:03.947702 140617721808768 trainer_lib.py:301] Configuring DataParallelism to replicate the model.\n",
            "I0919 06:59:03.947825 140617721808768 devices.py:76] schedule=continuous_train_and_eval\n",
            "I0919 06:59:03.947938 140617721808768 devices.py:77] worker_gpu=1\n",
            "I0919 06:59:03.948060 140617721808768 devices.py:78] sync=False\n",
            "W0919 06:59:03.948291 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/devices.py:139: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n",
            "\n",
            "W0919 06:59:03.948400 140617721808768 devices.py:141] Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\n",
            "I0919 06:59:03.949076 140617721808768 devices.py:170] datashard_devices: ['gpu:0']\n",
            "I0919 06:59:03.949193 140617721808768 devices.py:171] caching_devices: None\n",
            "I0919 06:59:03.949724 140617721808768 devices.py:172] ps_devices: ['gpu:0']\n",
            "I0919 06:59:03.980010 140617721808768 estimator.py:209] Using config: {'_save_checkpoints_secs': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 20, '_task_type': None, '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe3c182c050>, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_protocol': None, '_save_checkpoints_steps': 1000, '_keep_checkpoint_every_n_hours': 10000, '_session_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 0.95\n",
            "}\n",
            "allow_soft_placement: true\n",
            "graph_options {\n",
            "  optimizer_options {\n",
            "    global_jit_level: OFF\n",
            "  }\n",
            "}\n",
            ", '_model_dir': '/content/t2t_train/translate_enasl/transformer-transformer_tiny', 'use_tpu': False, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_experimental_max_worker_delay_secs': None, '_evaluation_master': '', '_eval_distribute': None, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7fe3c182c090>, '_environment': 'local', '_save_summary_steps': 100, 't2t_device_info': {'num_async_replicas': 1}}\n",
            "W0919 06:59:03.980232 140617721808768 model_fn.py:630] Estimator's model_fn (<function wrapping_model_fn at 0x7fe3c17346e0>) includes params argument, but params are not passed to Estimator.\n",
            "W0919 06:59:03.980819 140617721808768 trainer_lib.py:722] ValidationMonitor only works with --schedule=train_and_evaluate\n",
            "I0919 06:59:04.397921 140617721808768 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "I0919 06:59:04.398318 140617721808768 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "I0919 06:59:04.398827 140617721808768 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
            "W0919 06:59:04.415895 140617721808768 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/training_util.py:236: initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            ":::MLPv0.5.0 transformer 1568876344.429552078 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
            "I0919 06:59:04.429577 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876344.429552078 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
            "I0919 06:59:04.429791 140617721808768 problem.py:614] Reading data files from /content/t2t_data/translate_enasl-train*\n",
            "I0919 06:59:04.431545 140617721808768 problem.py:644] partition: 0 num_data_files: 100\n",
            ":::MLPv0.5.0 transformer 1568876344.432360888 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:872) input_order\n",
            "I0919 06:59:04.432375 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876344.432360888 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:872) input_order\n",
            "W0919 06:59:04.434650 140617721808768 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:654: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0919 06:59:04.434797 140617721808768 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0919 06:59:04.507504 140617721808768 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:172: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "W0919 06:59:04.519203 140617721808768 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/data_reader.py:31: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0919 06:59:04.550529 140617721808768 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:947: bucket_by_sequence_length (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.bucket_by_sequence_length(...)`.\n",
            "W0919 06:59:04.571182 140617721808768 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/data/experimental/ops/grouping.py:193: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0919 06:59:04.632111 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:1209: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0919 06:59:04.643870 140617721808768 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:1211: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "I0919 06:59:04.703135 140617721808768 estimator.py:1145] Calling model_fn.\n",
            ":::MLPv0.5.0 transformer 1568876345.109714985 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 4112, \"hidden_size\": 128}\n",
            "I0919 06:59:05.109746 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876345.109714985 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 4112, \"hidden_size\": 128}\n",
            "I0919 06:59:05.110040 140617721808768 t2t_model.py:1905] Setting T2TModel mode to 'train'\n",
            "W0919 06:59:05.192084 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:167: The name tf.summary.text is deprecated. Please use tf.compat.v1.summary.text instead.\n",
            "\n",
            ":::MLPv0.5.0 transformer 1568876347.552452087 (/tmp/tmphbdcER.py:100) model_hp_initializer_gain: 1.0\n",
            "W0919 06:59:09.868861 140617721808768 ag_logging.py:145] Entity <bound method PythonHandler.emit of <absl.logging.PythonHandler object at 0x7fe3e5e95550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: The global keyword is not yet supported.\n",
            "I0919 06:59:08.311079 140617721808768 api.py:452] :::MLPv0.5.0 transformer 1568876347.552452087 (/tmp/tmphbdcER.py:100) model_hp_initializer_gain: 1.0\n",
            "I0919 06:59:09.869776 140617721808768 api.py:255] Using variable initializer: uniform_unit_scaling\n",
            "I0919 06:59:10.398061 140617721808768 t2t_model.py:1905] Transforming feature 'inputs' with symbol_modality_4112_128.bottom\n",
            "I0919 06:59:10.569204 140617721808768 t2t_model.py:1905] Transforming feature 'targets' with symbol_modality_4112_128.targets_bottom\n",
            "I0919 06:59:10.595449 140617721808768 t2t_model.py:1905] Building model body\n",
            ":::MLPv0.5.0 transformer 1568876350.689111948 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.1\n",
            "I0919 06:59:10.689167 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876350.689111948 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.1\n",
            "W0919 06:59:10.689635 140617721808768 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:92: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            ":::MLPv0.5.0 transformer 1568876350.708523989 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
            "I0919 06:59:10.708554 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876350.708523989 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1568876350.710762024 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.1\n",
            "I0919 06:59:10.710798 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876350.710762024 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.1\n",
            ":::MLPv0.5.0 transformer 1568876350.712929964 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            "I0919 06:59:10.712959 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876350.712929964 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            "W0919 06:59:10.760837 140617721808768 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/common_layers.py:2926: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0919 06:59:11.216766 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/common_attention.py:1171: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            ":::MLPv0.5.0 transformer 1568876351.299108982 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 06:59:11.299133 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876351.299108982 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568876351.300326109 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 06:59:11.300345 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876351.300326109 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568876351.301609039 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.1\n",
            "I0919 06:59:11.301623 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876351.301609039 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.1\n",
            ":::MLPv0.5.0 transformer 1568876351.900655985 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 06:59:11.900692 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876351.900655985 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568876351.901971102 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 06:59:11.901992 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876351.901971102 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568876351.904124022 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.1\n",
            "I0919 06:59:11.904145 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876351.904124022 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.1\n",
            ":::MLPv0.5.0 transformer 1568876352.023427010 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
            "I0919 06:59:12.023499 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876352.023427010 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568876352.143963099 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.1\n",
            "I0919 06:59:12.143985 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876352.143963099 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.1\n",
            ":::MLPv0.5.0 transformer 1568876352.157694101 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
            "I0919 06:59:12.157711 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876352.157694101 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1568876352.158916950 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.1\n",
            "I0919 06:59:12.158932 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876352.158916950 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.1\n",
            ":::MLPv0.5.0 transformer 1568876352.160200119 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            "I0919 06:59:12.160217 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876352.160200119 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568876352.704729080 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 06:59:12.704756 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876352.704729080 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568876352.706001997 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 06:59:12.706018 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876352.706001997 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568876352.707173109 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.1\n",
            "I0919 06:59:12.707187 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876352.707173109 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.1\n",
            ":::MLPv0.5.0 transformer 1568876353.551392078 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 06:59:13.551419 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876353.551392078 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568876353.552750111 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 06:59:13.552766 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876353.552750111 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568876353.553894043 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.1\n",
            "I0919 06:59:13.553908 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876353.553894043 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.1\n",
            ":::MLPv0.5.0 transformer 1568876353.651209116 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
            "I0919 06:59:13.651235 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876353.651209116 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
            "I0919 06:59:13.681307 140617721808768 t2t_model.py:1905] Transforming body output with symbol_modality_4112_128.top\n",
            ":::MLPv0.5.0 transformer 1568876353.812272072 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:582) opt_learning_rate: \"DEFERRED: e3f6fda2-b49e-45d4-b39f-facb3652118f\"\n",
            "I0919 06:59:13.812303 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876353.812272072 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:582) opt_learning_rate: \"DEFERRED: e3f6fda2-b49e-45d4-b39f-facb3652118f\"\n",
            ":::MLPv0.5.0 transformer 1568876353.813292980 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:582) opt_learning_rate_warmup_steps: 8000\n",
            "I0919 06:59:13.813308 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876353.813292980 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:582) opt_learning_rate_warmup_steps: 8000\n",
            "W0919 06:59:13.813496 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/learning_rate.py:100: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "I0919 06:59:13.814862 140617721808768 learning_rate.py:29] Base learning rate: 2.000000\n",
            "I0919 06:59:13.827218 140617721808768 optimize.py:251] Trainable Variables Total size: 1453568\n",
            "I0919 06:59:13.827517 140617721808768 optimize.py:251] Non-trainable variables Total size: 5\n",
            "I0919 06:59:13.827728 140617721808768 optimize.py:89] Using optimizer Adam\n",
            ":::MLPv0.5.0 transformer 1568876353.828614950 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_name: \"Adam\"\n",
            "I0919 06:59:13.828630 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876353.828614950 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_name: \"Adam\"\n",
            ":::MLPv0.5.0 transformer 1568876353.829567909 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_beta1: 0.9\n",
            "I0919 06:59:13.829581 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876353.829567909 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_beta1: 0.9\n",
            ":::MLPv0.5.0 transformer 1568876353.830468893 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_beta2: 0.997\n",
            "I0919 06:59:13.830497 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876353.830468893 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_beta2: 0.997\n",
            ":::MLPv0.5.0 transformer 1568876353.831326008 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_epsilon: 1e-09\n",
            "I0919 06:59:13.831338 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876353.831326008 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/optimize.py:53) opt_hp_Adam_epsilon: 1e-09\n",
            "I0919 06:59:18.710423 140617721808768 estimator.py:1147] Done calling model_fn.\n",
            "I0919 06:59:18.712008 140617721808768 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0919 06:59:20.704879 140617721808768 monitored_session.py:240] Graph was finalized.\n",
            "2019-09-19 06:59:20.710421: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-09-19 06:59:20.710691: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556973c43480 executing computations on platform Host. Devices:\n",
            "2019-09-19 06:59:20.710728: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-09-19 06:59:20.712783: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-09-19 06:59:20.784385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 06:59:20.785276: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556973c43100 executing computations on platform CUDA. Devices:\n",
            "2019-09-19 06:59:20.785306: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-09-19 06:59:20.785503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 06:59:20.786177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-19 06:59:20.786506: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-19 06:59:20.787669: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-19 06:59:20.788793: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-19 06:59:20.789117: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-19 06:59:20.790563: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-19 06:59:20.791659: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-19 06:59:20.795006: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-19 06:59:20.795134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 06:59:20.795891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 06:59:20.796554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-19 06:59:20.796613: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-19 06:59:20.798347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-19 06:59:20.798378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-19 06:59:20.798391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-19 06:59:20.798545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 06:59:20.799318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 06:59:20.800161: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-09-19 06:59:20.800237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0919 06:59:20.801702 140617721808768 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0919 06:59:20.802938 140617721808768 saver.py:1280] Restoring parameters from /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt-800\n",
            "W0919 06:59:21.780116 140617721808768 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "2019-09-19 06:59:22.026126: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "I0919 06:59:22.058043 140617721808768 session_manager.py:500] Running local_init_op.\n",
            "I0919 06:59:22.150172 140617721808768 session_manager.py:502] Done running local_init_op.\n",
            "I0919 06:59:27.091386 140617721808768 basic_session_run_hooks.py:606] Saving checkpoints for 800 into /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt.\n",
            "2019-09-19 06:59:31.402085: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-19 06:59:41.610679: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:111] Filling up shuffle buffer (this may take a while): 292 of 512\n",
            "2019-09-19 06:59:48.783136: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:162] Shuffle buffer filled.\n",
            "I0919 06:59:48.916580 140617721808768 basic_session_run_hooks.py:262] loss = 3.8566022, step = 800\n",
            "I0919 07:00:01.629101 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 7.86528\n",
            "I0919 07:00:01.630527 140617721808768 basic_session_run_hooks.py:260] loss = 3.033149, step = 900 (12.714 sec)\n",
            "I0919 07:00:11.143414 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.5105\n",
            "I0919 07:00:11.145132 140617721808768 basic_session_run_hooks.py:260] loss = 3.4278057, step = 1000 (9.515 sec)\n",
            "I0919 07:00:20.537396 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.6451\n",
            "I0919 07:00:20.539426 140617721808768 basic_session_run_hooks.py:260] loss = 3.2277997, step = 1100 (9.394 sec)\n",
            "I0919 07:00:29.928560 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.6483\n",
            "I0919 07:00:29.930308 140617721808768 basic_session_run_hooks.py:260] loss = 3.0430822, step = 1200 (9.391 sec)\n",
            "I0919 07:00:39.297899 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.6731\n",
            "I0919 07:00:39.299570 140617721808768 basic_session_run_hooks.py:260] loss = 1.7031932, step = 1300 (9.369 sec)\n",
            "I0919 07:00:48.965121 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.3442\n",
            "I0919 07:00:48.967278 140617721808768 basic_session_run_hooks.py:260] loss = 2.5572336, step = 1400 (9.668 sec)\n",
            "I0919 07:00:58.528673 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.4564\n",
            "I0919 07:00:58.530680 140617721808768 basic_session_run_hooks.py:260] loss = 2.1123772, step = 1500 (9.563 sec)\n",
            "I0919 07:01:08.202640 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.3371\n",
            "I0919 07:01:08.205643 140617721808768 basic_session_run_hooks.py:260] loss = 2.2471445, step = 1600 (9.675 sec)\n",
            "I0919 07:01:17.958606 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.2501\n",
            "I0919 07:01:17.962203 140617721808768 basic_session_run_hooks.py:260] loss = 1.788485, step = 1700 (9.757 sec)\n",
            "I0919 07:01:27.849306 140617721808768 basic_session_run_hooks.py:606] Saving checkpoints for 1800 into /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt.\n",
            ":::MLPv0.5.0 transformer 1568876488.570975065 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
            "I0919 07:01:28.571003 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876488.570975065 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
            "I0919 07:01:28.571314 140617721808768 problem.py:614] Reading data files from /content/t2t_data/translate_enasl-dev*\n",
            "I0919 07:01:28.576189 140617721808768 problem.py:644] partition: 0 num_data_files: 1\n",
            "I0919 07:01:28.792124 140617721808768 estimator.py:1145] Calling model_fn.\n",
            ":::MLPv0.5.0 transformer 1568876489.215260983 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 4112, \"hidden_size\": 128}\n",
            "I0919 07:01:29.215292 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876489.215260983 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 4112, \"hidden_size\": 128}\n",
            "I0919 07:01:29.215672 140617721808768 t2t_model.py:1905] Setting T2TModel mode to 'eval'\n",
            "I0919 07:01:29.215949 140617721808768 t2t_model.py:1905] Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "I0919 07:01:29.216085 140617721808768 t2t_model.py:1905] Setting hparams.symbol_dropout to 0.0\n",
            "I0919 07:01:29.216206 140617721808768 t2t_model.py:1905] Setting hparams.label_smoothing to 0.0\n",
            "I0919 07:01:29.216331 140617721808768 t2t_model.py:1905] Setting hparams.attention_dropout to 0.0\n",
            "I0919 07:01:29.216458 140617721808768 t2t_model.py:1905] Setting hparams.dropout to 0.0\n",
            "I0919 07:01:29.216623 140617721808768 t2t_model.py:1905] Setting hparams.relu_dropout to 0.0\n",
            ":::MLPv0.5.0 transformer 1568876489.321314096 (/tmp/tmphbdcER.py:100) model_hp_initializer_gain: 1.0\n",
            "W0919 07:01:29.340208 140617721808768 ag_logging.py:145] Entity <bound method PythonHandler.emit of <absl.logging.PythonHandler object at 0x7fe3e5e95550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: The global keyword is not yet supported.\n",
            "I0919 07:01:29.323920 140617721808768 api.py:452] :::MLPv0.5.0 transformer 1568876489.321314096 (/tmp/tmphbdcER.py:100) model_hp_initializer_gain: 1.0\n",
            "I0919 07:01:29.341203 140617721808768 api.py:255] Using variable initializer: uniform_unit_scaling\n",
            "I0919 07:01:29.433813 140617721808768 t2t_model.py:1905] Transforming feature 'inputs' with symbol_modality_4112_128.bottom\n",
            "I0919 07:01:29.626713 140617721808768 t2t_model.py:1905] Transforming feature 'targets' with symbol_modality_4112_128.targets_bottom\n",
            "I0919 07:01:29.653578 140617721808768 t2t_model.py:1905] Building model body\n",
            ":::MLPv0.5.0 transformer 1568876489.750236034 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
            "I0919 07:01:29.750264 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876489.750236034 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568876489.752093077 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
            "I0919 07:01:29.752110 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876489.752093077 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1568876489.753667116 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
            "I0919 07:01:29.753683 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876489.753667116 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568876489.755260944 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            "I0919 07:01:29.755275 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876489.755260944 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568876490.385061979 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 07:01:30.385091 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876490.385061979 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568876490.386833906 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 07:01:30.386851 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876490.386833906 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568876490.388514996 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
            "I0919 07:01:30.388531 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876490.388514996 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568876490.762870073 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 07:01:30.762897 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876490.762870073 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568876490.764622927 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 07:01:30.764643 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876490.764622927 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568876490.766506910 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
            "I0919 07:01:30.766524 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876490.766506910 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568876490.865955114 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
            "I0919 07:01:30.865983 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876490.865955114 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568876490.980964899 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
            "I0919 07:01:30.980993 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876490.980964899 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568876490.983154058 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
            "I0919 07:01:30.983170 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876490.983154058 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1568876490.984874964 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
            "I0919 07:01:30.984896 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876490.984874964 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568876490.986687899 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            "I0919 07:01:30.986720 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876490.986687899 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568876491.502405882 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 07:01:31.502434 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876491.502405882 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568876491.504111052 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 07:01:31.504127 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876491.504111052 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568876491.505717993 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
            "I0919 07:01:31.505733 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876491.505717993 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568876492.107965946 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 07:01:32.107991 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876492.107965946 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568876492.109720945 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 07:01:32.109736 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876492.109720945 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568876492.111375093 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
            "I0919 07:01:32.111390 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876492.111375093 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568876492.194272995 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
            "I0919 07:01:32.194299 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568876492.194272995 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
            "I0919 07:01:32.226864 140617721808768 t2t_model.py:1905] Transforming body output with symbol_modality_4112_128.top\n",
            "W0919 07:01:32.365544 140617721808768 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/rouge.py:152: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0919 07:01:32.368253 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/metrics.py:553: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "W0919 07:01:33.439538 140617721808768 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/tensor2tensor/utils/t2t_model.py:1501: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "I0919 07:01:33.441854 140617721808768 estimator.py:1147] Done calling model_fn.\n",
            "I0919 07:01:33.463215 140617721808768 evaluation.py:255] Starting evaluation at 2019-09-19T07:01:33Z\n",
            "I0919 07:01:34.368202 140617721808768 monitored_session.py:240] Graph was finalized.\n",
            "2019-09-19 07:01:34.369287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:01:34.370035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-19 07:01:34.370152: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-19 07:01:34.370194: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-19 07:01:34.370246: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-19 07:01:34.370291: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-19 07:01:34.370336: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-19 07:01:34.370378: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-19 07:01:34.370432: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-19 07:01:34.370564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:01:34.371347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:01:34.372064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-19 07:01:34.372118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-19 07:01:34.372140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-19 07:01:34.372154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-19 07:01:34.372292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:01:34.373058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:01:34.373739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "I0919 07:01:34.375113 140617721808768 saver.py:1280] Restoring parameters from /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt-1800\n",
            "I0919 07:01:34.798043 140617721808768 session_manager.py:500] Running local_init_op.\n",
            "I0919 07:01:34.884583 140617721808768 session_manager.py:502] Done running local_init_op.\n",
            "I0919 07:01:39.017008 140617721808768 evaluation.py:167] Evaluation [10/100]\n",
            "I0919 07:01:39.982949 140617721808768 evaluation.py:167] Evaluation [20/100]\n",
            "I0919 07:01:41.617033 140617721808768 evaluation.py:167] Evaluation [30/100]\n",
            "I0919 07:01:41.844597 140617721808768 evaluation.py:275] Finished evaluation at 2019-09-19-07:01:41\n",
            "I0919 07:01:41.844913 140617721808768 estimator.py:2039] Saving dict for global step 1800: global_step = 1800, loss = 1.5124929, metrics-translate_enasl/targets/accuracy = 0.7400089, metrics-translate_enasl/targets/accuracy_per_sequence = 0.102200486, metrics-translate_enasl/targets/accuracy_top5 = 0.86527455, metrics-translate_enasl/targets/approx_bleu_score = 0.50234497, metrics-translate_enasl/targets/neg_log_perplexity = -1.5052173, metrics-translate_enasl/targets/rouge_2_fscore = 0.5612744, metrics-translate_enasl/targets/rouge_L_fscore = 0.7316542\n",
            "I0919 07:01:41.845604 140617721808768 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1800: /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt-1800\n",
            "I0919 07:01:42.002293 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 4.1591\n",
            "I0919 07:01:42.004261 140617721808768 basic_session_run_hooks.py:260] loss = 1.7218839, step = 1800 (24.042 sec)\n",
            "I0919 07:01:51.933957 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.0687\n",
            "I0919 07:01:51.936084 140617721808768 basic_session_run_hooks.py:260] loss = 0.9790531, step = 1900 (9.932 sec)\n",
            "I0919 07:02:01.784637 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.1516\n",
            "I0919 07:02:01.787198 140617721808768 basic_session_run_hooks.py:260] loss = 1.0178246, step = 2000 (9.851 sec)\n",
            "I0919 07:02:11.774391 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.0102\n",
            "I0919 07:02:11.776725 140617721808768 basic_session_run_hooks.py:260] loss = 0.53999376, step = 2100 (9.990 sec)\n",
            "I0919 07:02:21.722505 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.0522\n",
            "I0919 07:02:21.724836 140617721808768 basic_session_run_hooks.py:260] loss = 0.87269014, step = 2200 (9.948 sec)\n",
            "I0919 07:02:31.744160 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.9783\n",
            "I0919 07:02:31.746397 140617721808768 basic_session_run_hooks.py:260] loss = 0.48127308, step = 2300 (10.022 sec)\n",
            "I0919 07:02:41.823729 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.92114\n",
            "I0919 07:02:41.825992 140617721808768 basic_session_run_hooks.py:260] loss = 1.4421427, step = 2400 (10.080 sec)\n",
            "I0919 07:02:51.730173 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.0944\n",
            "I0919 07:02:51.732012 140617721808768 basic_session_run_hooks.py:260] loss = 1.0171775, step = 2500 (9.906 sec)\n",
            "I0919 07:03:01.580430 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.152\n",
            "I0919 07:03:01.583028 140617721808768 basic_session_run_hooks.py:260] loss = 0.8868016, step = 2600 (9.851 sec)\n",
            "I0919 07:03:11.524934 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.0558\n",
            "I0919 07:03:11.527050 140617721808768 basic_session_run_hooks.py:260] loss = 0.54565233, step = 2700 (9.944 sec)\n",
            "I0919 07:03:21.405033 140617721808768 basic_session_run_hooks.py:606] Saving checkpoints for 2800 into /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt.\n",
            "I0919 07:03:22.108566 140617721808768 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0919 07:03:22.220268 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.34987\n",
            "I0919 07:03:22.222604 140617721808768 basic_session_run_hooks.py:260] loss = 0.6365579, step = 2800 (10.696 sec)\n",
            "I0919 07:03:32.295612 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.92523\n",
            "I0919 07:03:32.297765 140617721808768 basic_session_run_hooks.py:260] loss = 0.5221667, step = 2900 (10.075 sec)\n",
            "I0919 07:03:42.200875 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.0957\n",
            "I0919 07:03:42.202755 140617721808768 basic_session_run_hooks.py:260] loss = 0.6094453, step = 3000 (9.905 sec)\n",
            "I0919 07:03:52.081620 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.1207\n",
            "I0919 07:03:52.083652 140617721808768 basic_session_run_hooks.py:260] loss = 0.34942767, step = 3100 (9.881 sec)\n",
            "I0919 07:04:02.104754 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.97695\n",
            "I0919 07:04:02.106616 140617721808768 basic_session_run_hooks.py:260] loss = 0.4637374, step = 3200 (10.023 sec)\n",
            "I0919 07:04:12.088977 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.0158\n",
            "I0919 07:04:12.091643 140617721808768 basic_session_run_hooks.py:260] loss = 0.64034677, step = 3300 (9.985 sec)\n",
            "I0919 07:04:22.174537 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.91508\n",
            "I0919 07:04:22.176234 140617721808768 basic_session_run_hooks.py:260] loss = 0.54663, step = 3400 (10.085 sec)\n",
            "I0919 07:04:32.170803 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.0038\n",
            "I0919 07:04:32.172580 140617721808768 basic_session_run_hooks.py:260] loss = 0.44229707, step = 3500 (9.996 sec)\n",
            "I0919 07:04:42.073102 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.0987\n",
            "I0919 07:04:42.078028 140617721808768 basic_session_run_hooks.py:260] loss = 0.4911402, step = 3600 (9.905 sec)\n",
            "I0919 07:04:52.080959 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.99209\n",
            "I0919 07:04:52.082750 140617721808768 basic_session_run_hooks.py:260] loss = 0.47151467, step = 3700 (10.005 sec)\n",
            "I0919 07:05:02.036556 140617721808768 basic_session_run_hooks.py:606] Saving checkpoints for 3800 into /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt.\n",
            "I0919 07:05:02.726520 140617721808768 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0919 07:05:02.835215 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.29866\n",
            "I0919 07:05:02.836986 140617721808768 basic_session_run_hooks.py:260] loss = 0.30967537, step = 3800 (10.754 sec)\n",
            "I0919 07:05:12.965147 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.87179\n",
            "I0919 07:05:12.967278 140617721808768 basic_session_run_hooks.py:260] loss = 0.30555654, step = 3900 (10.130 sec)\n",
            "I0919 07:05:23.349715 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.62966\n",
            "I0919 07:05:23.351989 140617721808768 basic_session_run_hooks.py:260] loss = 0.26626122, step = 4000 (10.385 sec)\n",
            "I0919 07:05:33.330075 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.0196\n",
            "I0919 07:05:33.331636 140617721808768 basic_session_run_hooks.py:260] loss = 0.31888667, step = 4100 (9.980 sec)\n",
            "I0919 07:05:43.509139 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.82413\n",
            "I0919 07:05:43.510781 140617721808768 basic_session_run_hooks.py:260] loss = 0.32061985, step = 4200 (10.179 sec)\n",
            "I0919 07:05:53.727674 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.78611\n",
            "I0919 07:05:53.729964 140617721808768 basic_session_run_hooks.py:260] loss = 0.44657043, step = 4300 (10.219 sec)\n",
            "I0919 07:06:03.893800 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.83661\n",
            "I0919 07:06:03.896462 140617721808768 basic_session_run_hooks.py:260] loss = 0.26732433, step = 4400 (10.167 sec)\n",
            "I0919 07:06:14.134057 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.76539\n",
            "I0919 07:06:14.137603 140617721808768 basic_session_run_hooks.py:260] loss = 0.25846246, step = 4500 (10.241 sec)\n",
            "I0919 07:06:24.302747 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.83406\n",
            "I0919 07:06:24.304436 140617721808768 basic_session_run_hooks.py:260] loss = 0.21388626, step = 4600 (10.167 sec)\n",
            "I0919 07:06:34.447892 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.85693\n",
            "I0919 07:06:34.450409 140617721808768 basic_session_run_hooks.py:260] loss = 0.35042405, step = 4700 (10.146 sec)\n",
            "I0919 07:06:44.415335 140617721808768 basic_session_run_hooks.py:606] Saving checkpoints for 4800 into /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt.\n",
            "I0919 07:06:45.103871 140617721808768 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0919 07:06:45.218386 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.28464\n",
            "I0919 07:06:45.220217 140617721808768 basic_session_run_hooks.py:260] loss = 0.3025708, step = 4800 (10.770 sec)\n",
            "I0919 07:06:55.482500 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.74268\n",
            "I0919 07:06:55.484277 140617721808768 basic_session_run_hooks.py:260] loss = 0.2263765, step = 4900 (10.264 sec)\n",
            "I0919 07:07:05.715569 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.77224\n",
            "I0919 07:07:05.717739 140617721808768 basic_session_run_hooks.py:260] loss = 0.22985318, step = 5000 (10.233 sec)\n",
            "I0919 07:07:15.701757 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 10.0138\n",
            "I0919 07:07:15.703634 140617721808768 basic_session_run_hooks.py:260] loss = 0.18129885, step = 5100 (9.986 sec)\n",
            "I0919 07:07:26.109407 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.60835\n",
            "I0919 07:07:26.116841 140617721808768 basic_session_run_hooks.py:260] loss = 0.25187528, step = 5200 (10.413 sec)\n",
            "I0919 07:07:36.315939 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.7976\n",
            "I0919 07:07:36.317859 140617721808768 basic_session_run_hooks.py:260] loss = 0.18604468, step = 5300 (10.201 sec)\n",
            "I0919 07:07:46.604644 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.71949\n",
            "I0919 07:07:46.607498 140617721808768 basic_session_run_hooks.py:260] loss = 0.2056425, step = 5400 (10.290 sec)\n",
            "I0919 07:07:56.862209 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.74888\n",
            "I0919 07:07:56.864257 140617721808768 basic_session_run_hooks.py:260] loss = 0.23570956, step = 5500 (10.257 sec)\n",
            "I0919 07:08:07.194869 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.67796\n",
            "I0919 07:08:07.196592 140617721808768 basic_session_run_hooks.py:260] loss = 0.26011586, step = 5600 (10.332 sec)\n",
            "I0919 07:08:17.525646 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.67986\n",
            "I0919 07:08:17.527610 140617721808768 basic_session_run_hooks.py:260] loss = 0.16893286, step = 5700 (10.331 sec)\n",
            "I0919 07:08:27.721170 140617721808768 basic_session_run_hooks.py:606] Saving checkpoints for 5800 into /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt.\n",
            "I0919 07:08:28.898354 140617721808768 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0919 07:08:29.026546 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 8.695\n",
            "I0919 07:08:29.028593 140617721808768 basic_session_run_hooks.py:260] loss = 0.20467384, step = 5800 (11.501 sec)\n",
            "I0919 07:08:39.183787 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.84517\n",
            "I0919 07:08:39.186892 140617721808768 basic_session_run_hooks.py:260] loss = 0.20981972, step = 5900 (10.158 sec)\n",
            "I0919 07:08:49.454238 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.73666\n",
            "I0919 07:08:49.455986 140617721808768 basic_session_run_hooks.py:260] loss = 0.24510945, step = 6000 (10.269 sec)\n",
            "I0919 07:08:59.894553 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.57829\n",
            "I0919 07:08:59.897936 140617721808768 basic_session_run_hooks.py:260] loss = 0.21325229, step = 6100 (10.442 sec)\n",
            "I0919 07:09:10.235332 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.67042\n",
            "I0919 07:09:10.238154 140617721808768 basic_session_run_hooks.py:260] loss = 0.24330395, step = 6200 (10.340 sec)\n",
            "I0919 07:09:20.665791 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.5874\n",
            "I0919 07:09:20.667568 140617721808768 basic_session_run_hooks.py:260] loss = 0.14442676, step = 6300 (10.429 sec)\n",
            "I0919 07:09:31.074814 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.607\n",
            "I0919 07:09:31.077563 140617721808768 basic_session_run_hooks.py:260] loss = 0.16758592, step = 6400 (10.410 sec)\n",
            "I0919 07:09:41.510155 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.5828\n",
            "I0919 07:09:41.512403 140617721808768 basic_session_run_hooks.py:260] loss = 0.16821532, step = 6500 (10.435 sec)\n",
            "I0919 07:09:51.828573 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.69142\n",
            "I0919 07:09:51.831842 140617721808768 basic_session_run_hooks.py:260] loss = 0.17479445, step = 6600 (10.319 sec)\n",
            "I0919 07:10:02.331547 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.52109\n",
            "I0919 07:10:02.333194 140617721808768 basic_session_run_hooks.py:260] loss = 0.15990938, step = 6700 (10.501 sec)\n",
            "I0919 07:10:12.942234 140617721808768 basic_session_run_hooks.py:606] Saving checkpoints for 6800 into /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt.\n",
            "I0919 07:10:13.673388 140617721808768 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0919 07:10:13.785523 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 8.7306\n",
            "I0919 07:10:13.787396 140617721808768 basic_session_run_hooks.py:260] loss = 0.14645565, step = 6800 (11.454 sec)\n",
            "I0919 07:10:24.286066 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.52331\n",
            "I0919 07:10:24.289645 140617721808768 basic_session_run_hooks.py:260] loss = 0.15925774, step = 6900 (10.502 sec)\n",
            "I0919 07:10:34.720712 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.58343\n",
            "I0919 07:10:34.722537 140617721808768 basic_session_run_hooks.py:260] loss = 0.18252009, step = 7000 (10.433 sec)\n",
            "I0919 07:10:45.437352 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.33134\n",
            "I0919 07:10:45.439358 140617721808768 basic_session_run_hooks.py:260] loss = 0.1798748, step = 7100 (10.717 sec)\n",
            "I0919 07:10:55.890836 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.56621\n",
            "I0919 07:10:55.893038 140617721808768 basic_session_run_hooks.py:260] loss = 0.18589991, step = 7200 (10.454 sec)\n",
            "I0919 07:11:06.365448 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.54684\n",
            "I0919 07:11:06.368165 140617721808768 basic_session_run_hooks.py:260] loss = 0.15393144, step = 7300 (10.475 sec)\n",
            "I0919 07:11:17.015094 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.39001\n",
            "I0919 07:11:17.017190 140617721808768 basic_session_run_hooks.py:260] loss = 0.20483482, step = 7400 (10.649 sec)\n",
            "I0919 07:11:27.462255 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.57199\n",
            "I0919 07:11:27.466020 140617721808768 basic_session_run_hooks.py:260] loss = 0.19314553, step = 7500 (10.449 sec)\n",
            "I0919 07:11:38.078608 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.41943\n",
            "I0919 07:11:38.084805 140617721808768 basic_session_run_hooks.py:260] loss = 0.15221299, step = 7600 (10.619 sec)\n",
            "I0919 07:11:48.672005 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.43978\n",
            "I0919 07:11:48.674022 140617721808768 basic_session_run_hooks.py:260] loss = 0.1842606, step = 7700 (10.589 sec)\n",
            "I0919 07:11:58.967111 140617721808768 basic_session_run_hooks.py:606] Saving checkpoints for 7800 into /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt.\n",
            ":::MLPv0.5.0 transformer 1568877119.677038908 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
            "I0919 07:11:59.677079 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877119.677038908 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
            "I0919 07:11:59.677392 140617721808768 problem.py:614] Reading data files from /content/t2t_data/translate_enasl-dev*\n",
            "I0919 07:11:59.679187 140617721808768 problem.py:644] partition: 0 num_data_files: 1\n",
            "I0919 07:11:59.906501 140617721808768 estimator.py:1145] Calling model_fn.\n",
            ":::MLPv0.5.0 transformer 1568877120.328252077 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 4112, \"hidden_size\": 128}\n",
            "I0919 07:12:00.328284 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877120.328252077 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 4112, \"hidden_size\": 128}\n",
            "I0919 07:12:00.328553 140617721808768 t2t_model.py:1905] Setting T2TModel mode to 'eval'\n",
            "I0919 07:12:00.328783 140617721808768 t2t_model.py:1905] Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "I0919 07:12:00.328897 140617721808768 t2t_model.py:1905] Setting hparams.symbol_dropout to 0.0\n",
            "I0919 07:12:00.328991 140617721808768 t2t_model.py:1905] Setting hparams.label_smoothing to 0.0\n",
            "I0919 07:12:00.329083 140617721808768 t2t_model.py:1905] Setting hparams.attention_dropout to 0.0\n",
            "I0919 07:12:00.329168 140617721808768 t2t_model.py:1905] Setting hparams.dropout to 0.0\n",
            "I0919 07:12:00.329252 140617721808768 t2t_model.py:1905] Setting hparams.relu_dropout to 0.0\n",
            ":::MLPv0.5.0 transformer 1568877120.433231115 (/tmp/tmphbdcER.py:100) model_hp_initializer_gain: 1.0\n",
            "W0919 07:12:00.451611 140617721808768 ag_logging.py:145] Entity <bound method PythonHandler.emit of <absl.logging.PythonHandler object at 0x7fe3e5e95550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: The global keyword is not yet supported.\n",
            "I0919 07:12:00.435713 140617721808768 api.py:452] :::MLPv0.5.0 transformer 1568877120.433231115 (/tmp/tmphbdcER.py:100) model_hp_initializer_gain: 1.0\n",
            "I0919 07:12:00.452455 140617721808768 api.py:255] Using variable initializer: uniform_unit_scaling\n",
            "I0919 07:12:00.544323 140617721808768 t2t_model.py:1905] Transforming feature 'inputs' with symbol_modality_4112_128.bottom\n",
            "I0919 07:12:01.065985 140617721808768 t2t_model.py:1905] Transforming feature 'targets' with symbol_modality_4112_128.targets_bottom\n",
            "I0919 07:12:01.098382 140617721808768 t2t_model.py:1905] Building model body\n",
            ":::MLPv0.5.0 transformer 1568877121.190251112 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
            "I0919 07:12:01.190278 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877121.190251112 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877121.192053080 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
            "I0919 07:12:01.192068 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877121.192053080 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1568877121.193592072 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
            "I0919 07:12:01.193605 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877121.193592072 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877121.195218086 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            "I0919 07:12:01.195250 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877121.195218086 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877121.475660086 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 07:12:01.475688 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877121.475660086 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568877121.477401972 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 07:12:01.477416 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877121.477401972 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877121.478950977 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
            "I0919 07:12:01.478966 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877121.478950977 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877121.862601042 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 07:12:01.862627 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877121.862601042 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568877121.864259958 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 07:12:01.864275 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877121.864259958 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877121.865834951 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
            "I0919 07:12:01.865850 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877121.865834951 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877121.966301918 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
            "I0919 07:12:01.966329 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877121.966301918 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877122.091006994 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
            "I0919 07:12:02.091043 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877122.091006994 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877122.094759941 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
            "I0919 07:12:02.094784 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877122.094759941 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1568877122.097632885 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
            "I0919 07:12:02.097651 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877122.097632885 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877122.100605011 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            "I0919 07:12:02.100629 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877122.100605011 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877122.616544008 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 07:12:02.616570 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877122.616544008 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568877122.618279934 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 07:12:02.618294 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877122.618279934 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877122.619844913 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
            "I0919 07:12:02.619859 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877122.619844913 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877123.209078074 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 07:12:03.209104 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877123.209078074 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568877123.210776091 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 07:12:03.210792 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877123.210776091 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877123.212322950 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
            "I0919 07:12:03.212337 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877123.212322950 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877123.289247990 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
            "I0919 07:12:03.289273 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877123.289247990 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
            "I0919 07:12:03.324372 140617721808768 t2t_model.py:1905] Transforming body output with symbol_modality_4112_128.top\n",
            "I0919 07:12:04.541198 140617721808768 estimator.py:1147] Done calling model_fn.\n",
            "I0919 07:12:04.563000 140617721808768 evaluation.py:255] Starting evaluation at 2019-09-19T07:12:04Z\n",
            "I0919 07:12:04.849447 140617721808768 monitored_session.py:240] Graph was finalized.\n",
            "2019-09-19 07:12:04.850430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:12:04.851216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-19 07:12:04.851314: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-19 07:12:04.851348: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-19 07:12:04.851379: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-19 07:12:04.851409: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-19 07:12:04.851432: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-19 07:12:04.851457: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-19 07:12:04.851499: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-19 07:12:04.851586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:12:04.852368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:12:04.853012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-19 07:12:04.853056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-19 07:12:04.853070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-19 07:12:04.853080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-19 07:12:04.853195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:12:04.853970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:12:04.854628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "I0919 07:12:04.855999 140617721808768 saver.py:1280] Restoring parameters from /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt-7800\n",
            "I0919 07:12:05.244230 140617721808768 session_manager.py:500] Running local_init_op.\n",
            "I0919 07:12:05.320554 140617721808768 session_manager.py:502] Done running local_init_op.\n",
            "I0919 07:12:09.223568 140617721808768 evaluation.py:167] Evaluation [10/100]\n",
            "I0919 07:12:10.203130 140617721808768 evaluation.py:167] Evaluation [20/100]\n",
            "I0919 07:12:11.883322 140617721808768 evaluation.py:167] Evaluation [30/100]\n",
            "I0919 07:12:12.096739 140617721808768 evaluation.py:275] Finished evaluation at 2019-09-19-07:12:12\n",
            "I0919 07:12:12.097232 140617721808768 estimator.py:2039] Saving dict for global step 7800: global_step = 7800, loss = 0.13621214, metrics-translate_enasl/targets/accuracy = 0.98280895, metrics-translate_enasl/targets/accuracy_per_sequence = 0.791198, metrics-translate_enasl/targets/accuracy_top5 = 0.996473, metrics-translate_enasl/targets/approx_bleu_score = 0.90596575, metrics-translate_enasl/targets/neg_log_perplexity = -0.12903653, metrics-translate_enasl/targets/rouge_2_fscore = 0.9249156, metrics-translate_enasl/targets/rouge_L_fscore = 0.93466985\n",
            "I0919 07:12:12.097987 140617721808768 estimator.py:2099] Saving 'checkpoint_path' summary for global step 7800: /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt-7800\n",
            "I0919 07:12:12.246449 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 4.24188\n",
            "I0919 07:12:12.248178 140617721808768 basic_session_run_hooks.py:260] loss = 0.16115169, step = 7800 (23.574 sec)\n",
            "I0919 07:12:22.725291 140617721808768 basic_session_run_hooks.py:692] global_step/sec: 9.54309\n",
            "I0919 07:12:22.727417 140617721808768 basic_session_run_hooks.py:260] loss = 0.14276646, step = 7900 (10.479 sec)\n",
            "I0919 07:12:33.111882 140617721808768 basic_session_run_hooks.py:606] Saving checkpoints for 8000 into /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt.\n",
            "I0919 07:12:33.837038 140617721808768 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            ":::MLPv0.5.0 transformer 1568877153.846338034 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
            "I0919 07:12:33.846362 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877153.846338034 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
            "I0919 07:12:33.846616 140617721808768 problem.py:614] Reading data files from /content/t2t_data/translate_enasl-dev*\n",
            "I0919 07:12:33.847945 140617721808768 problem.py:644] partition: 0 num_data_files: 1\n",
            "I0919 07:12:34.082001 140617721808768 estimator.py:1145] Calling model_fn.\n",
            ":::MLPv0.5.0 transformer 1568877154.502501011 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 4112, \"hidden_size\": 128}\n",
            "I0919 07:12:34.502533 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877154.502501011 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 4112, \"hidden_size\": 128}\n",
            "I0919 07:12:34.502832 140617721808768 t2t_model.py:1905] Setting T2TModel mode to 'eval'\n",
            "I0919 07:12:34.503031 140617721808768 t2t_model.py:1905] Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "I0919 07:12:34.503140 140617721808768 t2t_model.py:1905] Setting hparams.symbol_dropout to 0.0\n",
            "I0919 07:12:34.503242 140617721808768 t2t_model.py:1905] Setting hparams.label_smoothing to 0.0\n",
            "I0919 07:12:34.503334 140617721808768 t2t_model.py:1905] Setting hparams.attention_dropout to 0.0\n",
            "I0919 07:12:34.503417 140617721808768 t2t_model.py:1905] Setting hparams.dropout to 0.0\n",
            "I0919 07:12:34.503535 140617721808768 t2t_model.py:1905] Setting hparams.relu_dropout to 0.0\n",
            ":::MLPv0.5.0 transformer 1568877154.600764036 (/tmp/tmphbdcER.py:100) model_hp_initializer_gain: 1.0\n",
            "W0919 07:12:34.619857 140617721808768 ag_logging.py:145] Entity <bound method PythonHandler.emit of <absl.logging.PythonHandler object at 0x7fe3e5e95550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: The global keyword is not yet supported.\n",
            "I0919 07:12:34.603147 140617721808768 api.py:452] :::MLPv0.5.0 transformer 1568877154.600764036 (/tmp/tmphbdcER.py:100) model_hp_initializer_gain: 1.0\n",
            "I0919 07:12:34.620842 140617721808768 api.py:255] Using variable initializer: uniform_unit_scaling\n",
            "I0919 07:12:34.711353 140617721808768 t2t_model.py:1905] Transforming feature 'inputs' with symbol_modality_4112_128.bottom\n",
            "I0919 07:12:34.897259 140617721808768 t2t_model.py:1905] Transforming feature 'targets' with symbol_modality_4112_128.targets_bottom\n",
            "I0919 07:12:34.921884 140617721808768 t2t_model.py:1905] Building model body\n",
            ":::MLPv0.5.0 transformer 1568877155.022681952 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
            "I0919 07:12:35.022710 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877155.022681952 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877155.024558067 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
            "I0919 07:12:35.024574 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877155.024558067 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1568877155.026236057 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
            "I0919 07:12:35.026259 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877155.026236057 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877155.027883053 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            "I0919 07:12:35.027899 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877155.027883053 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877155.316535950 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 07:12:35.316569 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877155.316535950 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568877155.318170071 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 07:12:35.318190 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877155.318170071 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877155.319677114 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
            "I0919 07:12:35.319691 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877155.319677114 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877155.694869995 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 07:12:35.694896 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877155.694869995 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568877155.696633101 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 07:12:35.696650 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877155.696633101 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877155.698450089 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
            "I0919 07:12:35.698467 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877155.698450089 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877155.797375917 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
            "I0919 07:12:35.797404 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877155.797375917 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877156.426302910 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
            "I0919 07:12:36.426331 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877156.426302910 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877156.428101063 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
            "I0919 07:12:36.428117 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877156.428101063 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1568877156.429610968 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
            "I0919 07:12:36.429626 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877156.429610968 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877156.431076050 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            "I0919 07:12:36.431092 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877156.431076050 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877157.031439066 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 07:12:37.031533 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877157.031439066 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568877157.033655882 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 07:12:37.033711 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877157.033655882 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877157.035682917 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
            "I0919 07:12:37.035734 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877157.035682917 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877157.690747976 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 07:12:37.690776 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877157.690747976 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568877157.692409039 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 07:12:37.692425 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877157.692409039 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877157.693934917 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
            "I0919 07:12:37.693950 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877157.693934917 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877157.773034096 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
            "I0919 07:12:37.773062 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877157.773034096 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
            "I0919 07:12:37.806961 140617721808768 t2t_model.py:1905] Transforming body output with symbol_modality_4112_128.top\n",
            "I0919 07:12:38.660940 140617721808768 estimator.py:1147] Done calling model_fn.\n",
            "I0919 07:12:38.683913 140617721808768 evaluation.py:255] Starting evaluation at 2019-09-19T07:12:38Z\n",
            "I0919 07:12:38.978643 140617721808768 monitored_session.py:240] Graph was finalized.\n",
            "2019-09-19 07:12:38.979857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:12:38.980965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-19 07:12:38.981137: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-19 07:12:38.981275: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-19 07:12:38.981332: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-19 07:12:38.981398: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-19 07:12:38.981443: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-19 07:12:38.981531: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-19 07:12:38.981587: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-19 07:12:38.981730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:12:38.982584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:12:38.983270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-19 07:12:38.983314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-19 07:12:38.983329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-19 07:12:38.983339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-19 07:12:38.983473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:12:38.984220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:12:38.984961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "I0919 07:12:38.987139 140617721808768 saver.py:1280] Restoring parameters from /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt-8000\n",
            "I0919 07:12:39.386635 140617721808768 session_manager.py:500] Running local_init_op.\n",
            "I0919 07:12:39.467070 140617721808768 session_manager.py:502] Done running local_init_op.\n",
            "I0919 07:12:43.348937 140617721808768 evaluation.py:167] Evaluation [10/100]\n",
            "I0919 07:12:44.265199 140617721808768 evaluation.py:167] Evaluation [20/100]\n",
            "I0919 07:12:45.815450 140617721808768 evaluation.py:167] Evaluation [30/100]\n",
            "I0919 07:12:46.023220 140617721808768 evaluation.py:275] Finished evaluation at 2019-09-19-07:12:46\n",
            "I0919 07:12:46.023684 140617721808768 estimator.py:2039] Saving dict for global step 8000: global_step = 8000, loss = 0.14277354, metrics-translate_enasl/targets/accuracy = 0.9831593, metrics-translate_enasl/targets/accuracy_per_sequence = 0.78728604, metrics-translate_enasl/targets/accuracy_top5 = 0.9966599, metrics-translate_enasl/targets/approx_bleu_score = 0.9034597, metrics-translate_enasl/targets/neg_log_perplexity = -0.12685831, metrics-translate_enasl/targets/rouge_2_fscore = 0.92575055, metrics-translate_enasl/targets/rouge_L_fscore = 0.9338369\n",
            "I0919 07:12:46.024749 140617721808768 estimator.py:2099] Saving 'checkpoint_path' summary for global step 8000: /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt-8000\n",
            "I0919 07:12:46.330028 140617721808768 estimator.py:368] Loss for final step: 0.12880123.\n",
            ":::MLPv0.5.0 transformer 1568877166.340042114 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
            "I0919 07:12:46.340065 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877166.340042114 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/data_generators/problem.py:759) input_max_length: 256\n",
            "I0919 07:12:46.340253 140617721808768 problem.py:614] Reading data files from /content/t2t_data/translate_enasl-dev*\n",
            "I0919 07:12:46.341520 140617721808768 problem.py:644] partition: 0 num_data_files: 1\n",
            "I0919 07:12:46.556548 140617721808768 estimator.py:1145] Calling model_fn.\n",
            ":::MLPv0.5.0 transformer 1568877166.967788935 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 4112, \"hidden_size\": 128}\n",
            "I0919 07:12:46.967820 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877166.967788935 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:59) model_hp_embedding_shared_weights: {\"vocab_size\": 4112, \"hidden_size\": 128}\n",
            "I0919 07:12:46.968120 140617721808768 t2t_model.py:1905] Setting T2TModel mode to 'eval'\n",
            "I0919 07:12:46.968357 140617721808768 t2t_model.py:1905] Setting hparams.layer_prepostprocess_dropout to 0.0\n",
            "I0919 07:12:46.968508 140617721808768 t2t_model.py:1905] Setting hparams.symbol_dropout to 0.0\n",
            "I0919 07:12:46.968663 140617721808768 t2t_model.py:1905] Setting hparams.label_smoothing to 0.0\n",
            "I0919 07:12:46.968789 140617721808768 t2t_model.py:1905] Setting hparams.attention_dropout to 0.0\n",
            "I0919 07:12:46.968905 140617721808768 t2t_model.py:1905] Setting hparams.dropout to 0.0\n",
            "I0919 07:12:46.969041 140617721808768 t2t_model.py:1905] Setting hparams.relu_dropout to 0.0\n",
            ":::MLPv0.5.0 transformer 1568877167.070195913 (/tmp/tmphbdcER.py:100) model_hp_initializer_gain: 1.0\n",
            "W0919 07:12:47.088021 140617721808768 ag_logging.py:145] Entity <bound method PythonHandler.emit of <absl.logging.PythonHandler object at 0x7fe3e5e95550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: The global keyword is not yet supported.\n",
            "I0919 07:12:47.072685 140617721808768 api.py:452] :::MLPv0.5.0 transformer 1568877167.070195913 (/tmp/tmphbdcER.py:100) model_hp_initializer_gain: 1.0\n",
            "I0919 07:12:47.088862 140617721808768 api.py:255] Using variable initializer: uniform_unit_scaling\n",
            "I0919 07:12:47.787046 140617721808768 t2t_model.py:1905] Transforming feature 'inputs' with symbol_modality_4112_128.bottom\n",
            "I0919 07:12:47.961776 140617721808768 t2t_model.py:1905] Transforming feature 'targets' with symbol_modality_4112_128.targets_bottom\n",
            "I0919 07:12:47.986464 140617721808768 t2t_model.py:1905] Building model body\n",
            ":::MLPv0.5.0 transformer 1568877168.079860926 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
            "I0919 07:12:48.079885 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877168.079860926 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:186) model_hp_layer_postprocess_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877168.081404924 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
            "I0919 07:12:48.081422 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877168.081404924 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1568877168.082551956 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
            "I0919 07:12:48.082566 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877168.082551956 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877168.083853006 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            "I0919 07:12:48.083868 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877168.083853006 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877168.374126911 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 07:12:48.374154 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877168.374126911 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568877168.375372887 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 07:12:48.375387 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877168.375372887 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877168.376538992 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
            "I0919 07:12:48.376554 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877168.376538992 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877168.763124943 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 07:12:48.763153 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877168.763124943 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568877168.764475107 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 07:12:48.764503 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877168.764475107 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877168.765697002 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
            "I0919 07:12:48.765738 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877168.765697002 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/layers/transformer_layers.py:188) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877169.074115992 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
            "I0919 07:12:49.074146 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877169.074115992 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:101) model_hp_norm: {\"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877169.185854912 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
            "I0919 07:12:49.185914 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877169.185854912 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:202) model_hp_layer_postprocess_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877169.187427044 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
            "I0919 07:12:49.187443 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877169.187427044 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_hidden_layers: 2\n",
            ":::MLPv0.5.0 transformer 1568877169.188615084 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
            "I0919 07:12:49.188631 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877169.188615084 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877169.189795017 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            "I0919 07:12:49.189810 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877169.189795017 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_attention_dense: {\"num_heads\": 4, \"use_bias\": \"false\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877169.698848963 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 07:12:49.698874 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877169.698848963 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568877169.700445890 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 07:12:49.700462 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877169.700445890 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877169.701771975 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
            "I0919 07:12:49.701786 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877169.701771975 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877170.280061007 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            "I0919 07:12:50.280098 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877170.280061007 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_filter_dense: {\"filter_size\": 512, \"activation\": \"relu\", \"use_bias\": \"True\"}\n",
            ":::MLPv0.5.0 transformer 1568877170.282608032 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            "I0919 07:12:50.282632 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877170.282608032 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_ffn_output_dense: {\"use_bias\": \"True\", \"hidden_size\": 128}\n",
            ":::MLPv0.5.0 transformer 1568877170.285188913 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
            "I0919 07:12:50.285212 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877170.285188913 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:1295) model_hp_relu_dropout: 0.0\n",
            ":::MLPv0.5.0 transformer 1568877170.604417086 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
            "I0919 07:12:50.604445 140617721808768 mlperf_log.py:156] :::MLPv0.5.0 transformer 1568877170.604417086 (/usr/local/lib/python2.7/dist-packages/tensor2tensor/models/transformer.py:153) model_hp_norm: {\"hidden_size\": 128}\n",
            "I0919 07:12:50.636250 140617721808768 t2t_model.py:1905] Transforming body output with symbol_modality_4112_128.top\n",
            "I0919 07:12:51.477380 140617721808768 estimator.py:1147] Done calling model_fn.\n",
            "I0919 07:12:51.498656 140617721808768 evaluation.py:255] Starting evaluation at 2019-09-19T07:12:51Z\n",
            "I0919 07:12:51.782038 140617721808768 monitored_session.py:240] Graph was finalized.\n",
            "2019-09-19 07:12:51.782996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:12:51.783945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-09-19 07:12:51.784048: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-09-19 07:12:51.784105: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-09-19 07:12:51.784159: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-09-19 07:12:51.784211: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-09-19 07:12:51.784304: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-09-19 07:12:51.784349: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-09-19 07:12:51.784389: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-09-19 07:12:51.784525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:12:51.785346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:12:51.786056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-09-19 07:12:51.786108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-09-19 07:12:51.786145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-09-19 07:12:51.786159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-09-19 07:12:51.786322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:12:51.787079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-09-19 07:12:51.787754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10869 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "I0919 07:12:51.789021 140617721808768 saver.py:1280] Restoring parameters from /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt-8000\n",
            "I0919 07:12:52.144589 140617721808768 session_manager.py:500] Running local_init_op.\n",
            "I0919 07:12:52.212021 140617721808768 session_manager.py:502] Done running local_init_op.\n",
            "I0919 07:12:56.125704 140617721808768 evaluation.py:167] Evaluation [10/100]\n",
            "I0919 07:12:57.038057 140617721808768 evaluation.py:167] Evaluation [20/100]\n",
            "I0919 07:12:58.699068 140617721808768 evaluation.py:167] Evaluation [30/100]\n",
            "I0919 07:12:58.919064 140617721808768 evaluation.py:275] Finished evaluation at 2019-09-19-07:12:58\n",
            "I0919 07:12:58.919414 140617721808768 estimator.py:2039] Saving dict for global step 8000: global_step = 8000, loss = 0.14277354, metrics-translate_enasl/targets/accuracy = 0.9831593, metrics-translate_enasl/targets/accuracy_per_sequence = 0.78728604, metrics-translate_enasl/targets/accuracy_top5 = 0.9966599, metrics-translate_enasl/targets/approx_bleu_score = 0.9034597, metrics-translate_enasl/targets/neg_log_perplexity = -0.12685831, metrics-translate_enasl/targets/rouge_2_fscore = 0.92575055, metrics-translate_enasl/targets/rouge_L_fscore = 0.9338369\n",
            "I0919 07:12:58.919996 140617721808768 estimator.py:2099] Saving 'checkpoint_path' summary for global step 8000: /content/t2t_train/translate_enasl/transformer-transformer_tiny/model.ckpt-8000\n",
            ":::MLPv0.5.0 transformer 1568877178.920928955 (/usr/local/bin/t2t-trainer:28) run_final\n",
            "I0919 07:12:58.920953 140617721808768 mlperf_log.py:154] :::MLPv0.5.0 transformer 1568877178.920928955 (/usr/local/bin/t2t-trainer:28) run_final\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az5IKTy5ZFVJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "74361c34-4030-4ebb-ed78-d40d6fa4edd1"
      },
      "source": [
        "!git clone https://github.com/imatge-upc/speech2signs-2017-nmt\n",
        "!cp speech2signs-2017-nmt/ASLG-PC12/ENG-ASL_Train_0.046.en test_file.txt\n",
        "!sed -i '20,$ d' test_file.txt"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'speech2signs-2017-nmt'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Total 57 (delta 0), reused 0 (delta 0), pack-reused 57\n",
            "Unpacking objects: 100% (57/57), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln3aGn0hcX78",
        "colab_type": "code",
        "outputId": "97f2af2e-abdf-48bf-fb75-a4a2b7260eca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "!cat test_file.txt"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿membership of parliament see minutes\n",
            "approval of minutes of previous sitting see minutes\n",
            "membership of parliament see minutes\n",
            "documents received see minutes\n",
            "written statements and oral questions tabling see minutes\n",
            "petitions see minutes\n",
            "texts of agreements forwarded by the council see minutes\n",
            "action taken on parliament's resolutions see minutes\n",
            "closure of sitting\n",
            "the sitting was closed at 7.45 p.m. \n",
            "election of vice presidents of the european parliament deadline for submitting nominations see minutes\n",
            "the sitting was suspended at 12.40 p.m. and resumed at 3.00 p.m. \n",
            "election of quaestors of the european parliament deadline for submitting nominations see minutes\n",
            "the sitting was suspended at 3.25 p.m. and resumed at 6.00 p.m. \n",
            "agenda for next sitting see minutes\n",
            "closure of sitting\n",
            "the sitting was closed at 6.15 p.m. \n",
            "the sitting was opened at 9.35 a.m. \n",
            "documents received see minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Astes70F4vKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try translating\n",
        "!t2t-decoder --t2t_usr_dir tensor2tensor_problems/ \\\n",
        "  --data_dir=/content/t2t_data \\\n",
        "  --problem=translate_enasl \\\n",
        "  --model=transformer \\\n",
        "  --hparams_set=transformer_small \\\n",
        "  --output_dir=/content/t2t_train/translate_enasl/transformer-transformer_small \\\n",
        "  --decode_hparams=\"beam_size=4,alpha=.6\" \\\n",
        "  --decode_from_file=test_file.txt \\\n",
        "  --decode_to_file=translation.asl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HYHfIyfR_iQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "1c7b8221-c5c8-4a7d-cbed-e56215575cb0"
      },
      "source": [
        "!cat translation.asl"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeade\n",
            "adeadeadeadeadeadeadeadeadeadeadeadeadeamendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment\n",
            "adeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeade\n",
            "adeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeade\n",
            "adeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeade\n",
            "adeadeadeadeadeadeadeadeadeadeadeamendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment\n",
            "adeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadelislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislislis\n",
            "adeadeadeadeadeadeadeadeadeadeadeadeade2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 2008\n",
            "adeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeademan man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man\n",
            "adeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeademan man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man\n",
            "adeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeade\n",
            "adeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeade\n",
            "adeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeade\n",
            "adeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTALTAL\n",
            "adeadeadeadeadeadeadeadeadeamendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment amendment\n",
            "adeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeademan man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man man\n",
            "adeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeade\n",
            "quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality quality RURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURU\n",
            "adeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeadeade\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPfrgx5IYmp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
